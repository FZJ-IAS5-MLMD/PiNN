{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Customized model\n",
    "\n",
    "One of the ideas of PiNN is that different atomic neural networks shares similar building blocks.\n",
    "\n",
    "PiNN's abstraction of layers allows us to construct new network structures from those building blocks.  \n",
    "It also makes it easier to design novel layers that works along with existing ones.\n",
    "\n",
    "In this notebook, we will build a customized model by combining PiNN's Pi blocks with Behler's  \n",
    "element specific neural network. In this way, Pi blocks serves as a \"learnable\" feature generator \n",
    "for BPNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import tensorflow as tf\n",
    "import pinn.layers as l\n",
    "\n",
    "from glob import glob\n",
    "from pinn.models import potential_model\n",
    "from pinn.networks import pinn_network\n",
    "from pinn.utils import get_atomic_dress\n",
    "from pinn.datasets.qm9 import load_QM9_dataset\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom model function\n",
    "\n",
    "You can build a customized model simply by constructing a function to map the \n",
    "input `tensors` to prediction. Using the defined building blocks will make this\n",
    "a lot easier. The resulting function can be feed into the potential model, and \n",
    "you will be able to train, evaluate and use the model like any defined models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_network(tensors, atom_types, **kwargs):\n",
    "    # Use PiNN network function, but get the atomic properties instead of energy\n",
    "    atom_prop_all = pinn_network(tensors, to_return=1, **kwargs)\n",
    "    en = 0.0\n",
    "    n_sample = tf.shape(tensors['atoms'])[0]\n",
    "    # Use a larger network for energy prediction, and split the energy prediction\n",
    "    # layers for each element\n",
    "    for i in atom_types:\n",
    "        indices = tf.where(tf.equal(tensors['elem'],i))\n",
    "        atom_prop_i = tf.gather_nd(atom_prop_all, indices)\n",
    "        sample_id_i = tf.gather_nd(tensors['ind'][1], indices)\n",
    "        en += l.en_layer(sample_id_i, atom_prop_i, n_sample, [64,64,64],\n",
    "                         'separate_en_{}'.format(i))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluation\n",
    "\n",
    "After that, the model can be readily trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')\n",
    "dataset = lambda: load_QM9_dataset(filelist, split_ratio={'train':8, 'test':2})\n",
    "dress, error = get_atomic_dress(dataset()['train'],[1,6,7,8,9],max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/hybrid_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f17dbb95668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {'model_dir': '/tmp/hybrid_model',\n",
    "          'network': hybrid_network,\n",
    "          'netparam': {\n",
    "              'pre_level': 0,\n",
    "              'atom_types':[1, 6, 7, 8, 9],\n",
    "              'atomic_dress': dress},\n",
    "          'train': {\n",
    "              'learning_rate': 1e-3,\n",
    "              'en_scale': 627.5\n",
    "          }}\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=500)\n",
    "model = potential_model(params, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/hybrid_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 679.8525, step = 1\n",
      "INFO:tensorflow:global_step/sec: 8.50666\n",
      "INFO:tensorflow:loss = 133.58022, step = 501 (58.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.5613\n",
      "INFO:tensorflow:loss = 186.6181, step = 1001 (58.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0342\n",
      "INFO:tensorflow:loss = 173.83643, step = 1501 (33.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0357\n",
      "INFO:tensorflow:loss = 74.41773, step = 2001 (29.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5424\n",
      "INFO:tensorflow:loss = 67.311264, step = 2501 (30.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6709\n",
      "INFO:tensorflow:loss = 58.462902, step = 3001 (29.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7944\n",
      "INFO:tensorflow:loss = 105.60572, step = 3501 (29.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4197\n",
      "INFO:tensorflow:loss = 56.29804, step = 4001 (30.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6418\n",
      "INFO:tensorflow:loss = 29.022667, step = 4501 (30.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5391\n",
      "INFO:tensorflow:loss = 64.9411, step = 5001 (30.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7649\n",
      "INFO:tensorflow:loss = 45.564335, step = 5501 (29.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.751\n",
      "INFO:tensorflow:loss = 42.864014, step = 6001 (29.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8885\n",
      "INFO:tensorflow:loss = 63.169044, step = 6501 (29.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.885\n",
      "INFO:tensorflow:loss = 35.692394, step = 7001 (29.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6601\n",
      "INFO:tensorflow:loss = 29.11159, step = 7501 (30.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7902\n",
      "INFO:tensorflow:loss = 25.637339, step = 8001 (29.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5117\n",
      "INFO:tensorflow:loss = 29.517973, step = 8501 (30.280 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8973 into /tmp/hybrid_model/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-30-21:23:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/hybrid_model/model.ckpt-8973\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-30-21:23:29\n",
      "INFO:tensorflow:Saving dict for global step 8973: ENG_MAE = 3.948375, ENG_RMSE = 5.634411, global_step = 8973, loss = 31.746582\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8973: /tmp/hybrid_model/model.ckpt-8973\n",
      "INFO:tensorflow:global_step/sec: 10.8365\n",
      "INFO:tensorflow:loss = 34.45479, step = 9001 (46.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5724\n",
      "INFO:tensorflow:loss = 29.707607, step = 9501 (30.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/hybrid_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-30-21:24:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/hybrid_model/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-30-21:24:47\n",
      "INFO:tensorflow:Saving dict for global step 10000: ENG_MAE = 3.7595446, ENG_RMSE = 5.360081, global_step = 10000, loss = 28.730474\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/hybrid_model/model.ckpt-10000\n",
      "INFO:tensorflow:Loss for final step: 25.612349.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'ENG_MAE': 3.7595446,\n",
       "  'ENG_RMSE': 5.360081,\n",
       "  'loss': 28.730474,\n",
       "  'global_step': 10000},\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the datasets\n",
    "pre_fn = lambda tensors: pinn_network(tensors, preprocess=True, **params['netparam'])\n",
    "train = lambda: dataset()['train'].cache().repeat().shuffle(1000).batch(100).map(pre_fn, 8)\n",
    "test = lambda: dataset()['test'].cache().repeat().batch(100).map(pre_fn, 8)\n",
    "\n",
    "# Running specs\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1e4)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Our hybrid model beats the original PiNN at the cost of slower training for this test, \n",
    "although both model have not reached their full potential. Feel free to look into the \n",
    "definitions of `networks` & their `layers` and improve them with your custom models!\n",
    "\n",
    "**Note** You can reuse a model given the same network function, however, there's \n",
    "currently no way to recover a model if you lost you original function definition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
