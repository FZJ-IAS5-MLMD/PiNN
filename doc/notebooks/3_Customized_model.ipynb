{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Customized model\n",
    "\n",
    "One of the ideas of PiNN is that different atomic neural networks shares similar building blocks.\n",
    "\n",
    "PiNN's abstraction of layers allows us to construct new network structures from those building blocks.  \n",
    "It also makes it easier to design novel layers that works along with existing ones.\n",
    "\n",
    "In this notebook, we will build a customized model by combining PiNN's Pi blocks with Behler's  \n",
    "element specific neural network. In this way, Pi blocks serves as a \"learnable\" feature generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinn.layers as l\n",
    "import pinn.filters as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_network(tensors):\n",
    "    filters = {\n",
    "        f.sparsify()\n",
    "        f.atomic_onehot()\n",
    "        f.atomic_dress(dress={1:10,6:3})\n",
    "        f.naive_nl(4)(tensors)\n",
    "        f.symm_func()(tensors)\n",
    "        f.pi_basis()(tensors)}\n",
    "    for f in filters:\n",
    "        f(tensors)\n",
    "    # Define the filters, Note that you can include a pre_level option\n",
    "    # to optimize the input pipline.\n",
    "    \n",
    "    \n",
    "    # PiNN blocks copied from pinn.networks.\n",
    "    # After several blocks, the updated atomic features are stored in nodes[1] .\n",
    "    \n",
    "    # BPNN blocks copied from pinn.networks.\n",
    "    \n",
    "    # Generate the final predictions (total energy).\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluation\n",
    "\n",
    "After that, the model can be readily trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'network':hybrid_network}\n",
    "model = potential_model(params)\n",
    "# Dataset and training specs\n",
    "datasets = load_QM9_dataset('dsgn16/*', split_ratio={'train':8, 'test':2})\n",
    "train = lambda: datasets['train']().repeat().batch(100)\n",
    "test = lambda: datasets['test']().repeat().batch(10)\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1000)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)\n",
    "# Run the training\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "You can also save the parameters of custom models for later use, however,  \n",
    "there's currently no way to recover a model if you lost the original function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
