{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Customized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data list dataset\n",
    "\n",
    "Suppose your dataset can be represented as a list and each data point can \n",
    "be accessed separately with some function.\n",
    "The list dataset descriptor helps you to transform your reader function to \n",
    "a dataset loader, with a handy option to split your dataset.\n",
    "The list can be your list of filenames of structures, or identifiers to \n",
    "retrive you data points, e.g. ID from some online database.\n",
    "\n",
    "The advantage of this approach is that you only need to write the reader for \n",
    "one data point, \n",
    "and you can get the tensorflow dataset objects with reasonably optimized IO.\n",
    "Later, it's also easy to convert your dataset into the TFRecord format \n",
    "if you need to train on the cloud or further import the IO.\n",
    "\n",
    "We'll demonstration with a list of ASE atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "datalist = [Atoms(elem) for elem in ['Cu', 'Ag', 'Au']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of training ANN potentials, you typically need to provide the \n",
    "elements, coordinates and potential energy of a struture. \n",
    "In addition, you need to specify the maximum number of atoms in one structure\n",
    "in advance.\n",
    "\n",
    "Your reader function should take one list element as input, \n",
    "and return a dictionary consisting of:\n",
    "\n",
    "- `'atoms'`: the elements of shape [n_atoms]\n",
    "- `'coord'`: the coordinates of shape [n_atoms, 3]\n",
    "- `'e_data'`: a single number\n",
    "\n",
    "After you have got your reader function, decorate it with the `list_loader`\n",
    "decorater to transform it into a dataset loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.datasets.base import list_loader\n",
    "\n",
    "@list_loader()\n",
    "def load_ase_list(atoms, n_atoms):\n",
    "    import numpy as np\n",
    "    coord = atoms.positions\n",
    "    elems = atoms.numbers\n",
    "    # Currently, we demand all the import structures to have the same shape.\n",
    "    # If atoms have different number of atoms, we have to pad them with zeros.\n",
    "    to_pad = n_atoms - len(atoms)\n",
    "    elems = np.pad(elems, [0,to_pad], 'constant')\n",
    "    coord = np.pad(coord, [[0,to_pad], [0,0]], 'constant')\n",
    "\n",
    "    data = {'atoms': elems,\n",
    "            'coord': coord,\n",
    "            'e_data': 0.0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, you've got your customized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atoms': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = load_ase_list(datalist, n_atoms=1)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to import more complex dataset, say, to include more \n",
    "features or labels, you shall consider writing a formatter function \n",
    "to define your dataset structure.\n",
    "\n",
    "For example, we add a molecular weight entry to the dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_formater(n_atoms):\n",
    "    import tensorflow as tf\n",
    "    format_dict = {\n",
    "    'atoms': {'dtype':  tf.int32,   'shape': [n_atoms]},\n",
    "    'coord': {'dtype':  tf.float32, 'shape': [n_atoms, 3]},\n",
    "    'e_data': {'dtype': tf.float32, 'shape': []},\n",
    "    'mw_data': {'dtype': tf.float32, 'shape': []}}\n",
    "    return format_dict\n",
    "\n",
    "@list_loader(formater=my_formater)\n",
    "def load_ase_list(atoms, n_atoms):\n",
    "    import numpy as np\n",
    "    coord = atoms.positions\n",
    "    elems = atoms.numbers\n",
    "\n",
    "    to_pad = n_atoms - len(atoms)\n",
    "    elems = np.pad(elems, [0,to_pad], 'constant')\n",
    "    coord = np.pad(coord, [[0,to_pad], [0,0]], 'constant')\n",
    "\n",
    "    data = {'atoms': elems,\n",
    "            'coord': coord,\n",
    "            'e_data': 0.0,\n",
    "            'mw_data': atoms.get_masses().sum()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atoms': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0, 'mw_data': 63.546}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_ase_list(datalist, n_atoms=1)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
