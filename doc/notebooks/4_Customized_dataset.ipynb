{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Customized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data list dataset\n",
    "\n",
    "Suppose your dataset can be represented as a list and each data point can \n",
    "be accessed separately with some function.\n",
    "\n",
    "The list dataset descriptor helps you to transform your reader function to \n",
    "a dataset loader, with handy options to split your dataset.\n",
    "The list can be your list of filenames of structures, or identifiers to \n",
    "retrive you data points, e.g. ID from some online database.\n",
    "\n",
    "The advantage of this approach is that you only need to write the reader for \n",
    "one data point, \n",
    "and you can get the tensorflow dataset objects with reasonably optimized IO.\n",
    "Later, it's also easy to convert your dataset into the TFRecord format \n",
    "if you need to train on the cloud or further import the IO.\n",
    "\n",
    "We'll demonstration with a list of ASE atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "datalist = [Atoms(elem) for elem in ['Cu', 'Ag', 'Au']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of training ANN potentials, you typically need to provide the \n",
    "elements, coordinates and potential energy of a struture. \n",
    "In addition, you need to specify the maximum number of atoms in one structure\n",
    "in advance.\n",
    "\n",
    "Your reader function should take one list element as input, \n",
    "and return a dictionary consisting of:\n",
    "\n",
    "- `'atoms'`: the elements of shape [n_atoms]\n",
    "- `'coord'`: the coordinates of shape [n_atoms, 3]\n",
    "- `'e_data'`: a single number\n",
    "\n",
    "After you have got your reader function, decorate it with the `list_loader`\n",
    "decorator to transform it into a dataset loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.io import list_loader\n",
    "\n",
    "@list_loader()\n",
    "def load_ase_list(atoms):\n",
    "    import numpy as np\n",
    "    data = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'e_data': 0.0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, you've got your customized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force and cell\n",
    "\n",
    "By default the list loader expects the loader to return the elements, coordinates and \n",
    "total energy of the atoms.\n",
    "It is also usual to have nuclei forces and pbc in the training data.\n",
    "\n",
    "The default behavior of list_loader can be changed with `pbc` and `force` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0, 'cell': array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32), 'f_data': array([[0., 0., 0.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "@list_loader(pbc=True, force=True)\n",
    "def load_ase_list(atoms):\n",
    "    import numpy as np\n",
    "    data = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'cell': atoms.cell,\n",
    "            'f_data': np.zeros_like(atoms.positions),\n",
    "            'e_data': 0.0}\n",
    "    return data\n",
    "\n",
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format dict\n",
    "\n",
    "For even more complext dataset structure, you can instead supply a format_dict\n",
    "to build your list loader.\n",
    "Note that in the current version, the dataset is expected to be \n",
    "always a dictionary of tensors\n",
    "\n",
    "For example, we add a molecular weight entry to the dataset here.\n",
    "The format dict should provide the shape and datatype of each \n",
    "entry. \n",
    "In the case that certain dimension is unknow, e.g. the number of atoms,\n",
    "use `None` as the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict = {\n",
    "    'elems': {'dtype':  tf.int32,   'shape': [None]},\n",
    "    'coord': {'dtype':  tf.float32, 'shape': [None, 3]},\n",
    "    'e_data': {'dtype': tf.float32, 'shape': []},\n",
    "    'mw_data': {'dtype': tf.float32, 'shape': []}}\n",
    "\n",
    "@list_loader(format_dict=format_dict)\n",
    "def load_ase_list(atoms):\n",
    "    data = {'elems': atoms.numbers,\n",
    "            'coord': atoms.positions,\n",
    "            'e_data': 0.0,\n",
    "            'mw_data': atoms.get_masses().sum()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elems': array([29], dtype=int32), 'coord': array([[0., 0., 0.]], dtype=float32), 'e_data': 0.0, 'mw_data': 63.546}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_ase_list(datalist)['train']\n",
    "d = dataset.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading trajectories\n",
    "\n",
    "It's rather common to have trajectories as training data. \n",
    "However, trajectories are harder to handle compared to lists as \n",
    "it's not trivial how many data points are there and how should they be splitted.\n",
    "\n",
    "One solution is to load all the data into the memory once.\n",
    "A more sophesticated solution is to quickly scan through the dataset and \n",
    "get a list of \"positions\" which can be used to read a particular frame.\n",
    "\n",
    "You might want to look into `pinn.io.runner`\n",
    "if you would like to implement something like that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
