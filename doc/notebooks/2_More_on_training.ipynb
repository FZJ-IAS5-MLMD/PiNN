{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. More on training\n",
    "This notebooks covers more details on tweaking and optimizing the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from pinn.networks import pinn_network\n",
    "from pinn.utils import get_atomic_dress\n",
    "from pinn.models import potential_model\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the pipeline\n",
    "### Caching\n",
    "Caching stores the decoded dataset in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of testing, we use only 1000 samples from QM9\n",
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')[:1000]\n",
    "dataset = lambda: load_qm9(filelist, split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "87.5 ms ± 3.58 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        sess.run(tensors) # \"Warm up\" the graph\n",
    "    %timeit sess.run(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This speed indicates the IO limit of our current setting.\n",
    "\n",
    "Now let's cache the dataset to the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 µs ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        sess.run(tensors) # \"Warm up\" the graph, dataset is cached here\n",
    "    %timeit sess.run(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "You might also see a notable difference in the performance with and without preprocessing, this is especially helpful when you are training with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yunqi/work/pinn_proj/PiNN_dev/pinn/layers.py:80: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/yunqi/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "36.3 ms ± 3.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = dataset().cache().repeat().apply(sparse_batch(100))\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinn_network(tensors, pre_level=0)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pinn network provides two levels of preprocessing:\n",
    "\n",
    "- pre_level = 1 computes the atomic dress and the neighbour list\n",
    "- pre_level = 2 further computes everything not trainable (the symmetry function and the pi basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.6 ms ± 1.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "pre_fn = lambda tensors: pinn_network(tensors, pre_level=1, preprocess=True)\n",
    "d = dataset().cache().repeat().apply(sparse_batch(100)).map(pre_fn, num_parallel_calls=16)\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinn_network(tensors, pre_level=1)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1 ms ± 1.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "pre_fn = lambda tensors: pinn_network(tensors, pre_level=2, preprocess=True)\n",
    "d = dataset().cache().repeat().apply(sparse_batch(100)).map(pre_fn, num_parallel_calls=16)\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinn_network(tensors, pre_level=2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even cache the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.6 ms ± 2.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "pre_fn = lambda tensors: pinn_network(tensors, pre_level=2, preprocess=True)\n",
    "d = dataset().apply(sparse_batch(100)).map(pre_fn).cache().repeat()\n",
    "tensors = d.make_one_shot_iterator().get_next()\n",
    "output = pinn_network(tensors, pre_level=2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(output)\n",
    "    %timeit sess.run(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomic dress\n",
    "As is in many machine learning tasks, scaling and aligning the labels can \n",
    "enhance the performance of the models, and avoid numerical instability.\n",
    "\n",
    "For datasets like QM9, we can assign a atomic energy to each atom according\n",
    "to their elements to approximate the total energy. This can be done by simple linear optimizing. We provide a simple tool to generate such \"atomic dress\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')\n",
    "dataset = lambda: load_qm9(filelist, split={'train':8, 'test':2})\n",
    "dress, error = get_atomic_dress(dataset()['train'],[1,6,7,8,9],max_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the atomic dress convert the QM9 energies to a \"normal\" distribution.\n",
    "It also gives us some sense about the relative distribution of energies, and \n",
    "how much our neural network improves from the naive guess of atomic dress.\n",
    "\n",
    "After applying the atomic dress, turns out the distribution of our training set \n",
    "is only about 0.05 Hartree, or 30 kcal/mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.6039418437152411,\n",
       " 6: -38.07358460885415,\n",
       " 7: -54.75154708631868,\n",
       " 8: -75.22503739913694,\n",
       " 9: -99.87073186940984}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(error,50)\n",
    "dress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with the optimized pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {'model_dir': '/tmp/PiNN_QM9_pipeline',\n",
    "          'network': 'pinn_network',\n",
    "          'netparam': {\n",
    "              'pre_level': 2,\n",
    "              'atom_types':[1, 6, 7, 8, 9],\n",
    "              'atomic_dress': dress},\n",
    "          'train': {\n",
    "              'learning_rate': 1e-3, # Relatively large learning rate\n",
    "              'en_scale': 627.5 # Here we scale the model to kcal/mol\n",
    "          }}\n",
    "\n",
    "# The logging behaviour of estimator can be controlled here\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=500)\n",
    "\n",
    "# Preprocessing the datasets\n",
    "pre_fn = lambda tensors: pinn_network(tensors, preprocess=True, **params['netparam'])\n",
    "train = lambda: dataset()['train'].cache().repeat().shuffle(1000).apply(sparse_batch(100)).map(pre_fn, 8)\n",
    "test = lambda: dataset()['test'].cache().repeat().apply(sparse_batch(100)).map(pre_fn, 8)\n",
    "\n",
    "# Running specs\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=1e4)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/PiNN_QM9_pipeline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7086b1c0b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/PiNN_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:loss = 884.91095, step = 1\n",
      "INFO:tensorflow:global_step/sec: 13.6697\n",
      "INFO:tensorflow:loss = 181.90857, step = 501 (36.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6444\n",
      "INFO:tensorflow:loss = 223.97652, step = 1001 (36.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7218\n",
      "INFO:tensorflow:loss = 102.54984, step = 1501 (29.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0526\n",
      "INFO:tensorflow:loss = 95.56961, step = 2001 (27.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0946\n",
      "INFO:tensorflow:loss = 95.20323, step = 2501 (27.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6253\n",
      "INFO:tensorflow:loss = 64.58885, step = 3001 (28.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2027\n",
      "INFO:tensorflow:loss = 38.12014, step = 3501 (27.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0378\n",
      "INFO:tensorflow:loss = 42.759766, step = 4001 (27.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8693\n",
      "INFO:tensorflow:loss = 64.06951, step = 4501 (27.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0179\n",
      "INFO:tensorflow:loss = 39.82077, step = 5001 (27.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.723\n",
      "INFO:tensorflow:loss = 67.52896, step = 5501 (29.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4352\n",
      "INFO:tensorflow:loss = 57.85945, step = 6001 (28.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9004\n",
      "INFO:tensorflow:loss = 32.298183, step = 6501 (27.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9142\n",
      "INFO:tensorflow:loss = 51.77696, step = 7001 (27.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8931\n",
      "INFO:tensorflow:loss = 28.079971, step = 7501 (27.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8818\n",
      "INFO:tensorflow:loss = 25.574047, step = 8001 (27.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9586\n",
      "INFO:tensorflow:loss = 38.37402, step = 8501 (27.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1209\n",
      "INFO:tensorflow:loss = 33.86344, step = 9001 (29.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3432\n",
      "INFO:tensorflow:loss = 29.340754, step = 9501 (30.594 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/PiNN_QM9_pipeline/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-13T15:22:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/PiNN_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-13-15:22:33\n",
      "INFO:tensorflow:Saving dict for global step 10000: METRICS/ENG_MAE = 3.7256644, METRICS/ENG_RMSE = 5.2280016, global_step = 10000, loss = 27.331995\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/PiNN_QM9_pipeline/model.ckpt-10000\n",
      "INFO:tensorflow:Loss for final step: 24.780613.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'METRICS/ENG_MAE': 3.7256644,\n",
       "  'METRICS/ENG_RMSE': 5.2280016,\n",
       "  'loss': 27.331995,\n",
       "  'global_step': 10000},\n",
       " [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = potential_model(params, config)\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "It's recommended to monitor the training with Tensorboard instead of the stdout here.  \n",
    "Try `tensorboard --logdir /tmp`, and you can probably see this.\n",
    "\n",
    "![](tensorboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization with tf.Estimator\n",
    "\n",
    "The estimator api makes it extremely easy to train on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you have two cards\n",
    "distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\n",
    "config = tf.estimator.RunConfig(train_distribute=distribution)\n",
    "model = potential_model(params, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Congratulations! You can now train atomic neural networks with \n",
    "state-of-art accuracy and speed.\n",
    "\n",
    "\n",
    "But there's more. With PiNN, the components of ANNs are modulized.\n",
    "Read following notebooks to see how you can build you own ANN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
